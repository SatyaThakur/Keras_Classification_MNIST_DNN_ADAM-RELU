{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7rc2"
    },
    "colab": {
      "name": "Classification_MNIST_DNN_Keras_ADAM_RELU.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SatyaThakur/Keras_Classification_MNIST_DNN_ADAM-RELU/blob/master/Classification_MNIST_DNN_Keras_ADAM_RELU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9qexGhklF3XL",
        "colab_type": "text"
      },
      "source": [
        "### Load tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sty5brbLSY9r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "outputId": "14a1f0da-c144-458c-c27a-e9b8a5a5ff35"
      },
      "source": [
        "pip install tensorflow==1.14.0"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow==1.14.0 in /usr/local/lib/python3.6/dist-packages (1.14.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.3.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.18.4)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.12.1)\n",
            "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.14.0)\n",
            "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.14.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.12.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.29.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.9.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.1.2)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.34.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.2.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.0.8)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.8.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.1.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (3.10.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (47.1.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.2.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14.0) (2.10.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (1.6.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LreZ6acFF3XM",
        "colab_type": "code",
        "outputId": "ab6028c0-2522-471b-a6c8-ec5313e70db0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 440
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.reset_default_graph()\n",
        "tf.set_random_seed(42)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OaXF8xxGF3XR",
        "colab_type": "text"
      },
      "source": [
        "### Collect Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SljXdMvNF3XS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 840
        },
        "outputId": "877c700a-6aa3-4eb8-8edd-939fe18efb13"
      },
      "source": [
        "(trainX, trainY),(testX, testY) = tf.keras.datasets.mnist.load_data()\n",
        "trainX"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]]], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VToqqTuwF3XU",
        "colab_type": "text"
      },
      "source": [
        "### Convert Output label to multiple values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PiKjJOteF3XV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "3c02ce80-d62c-4622-f123-dfe7538f827b"
      },
      "source": [
        "trainY = tf.keras.utils.to_categorical(trainY, num_classes=10)\n",
        "testY = tf.keras.utils.to_categorical(testY, num_classes=10)\n",
        "trainY"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [1., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 1., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pydeqvLtF3XZ",
        "colab_type": "text"
      },
      "source": [
        "## Build the Graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2XnCQoIPF3Xa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Initialize model, reshape & normalize data\n",
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Reshape((784,),input_shape=(28,28,)))\n",
        "model.add(tf.keras.layers.BatchNormalization())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JCohgLYF3Xd",
        "colab_type": "text"
      },
      "source": [
        "### Apply ReLU and Dropout"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trHOvpwqF3Xd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "a80cd015-2f6b-4a1c-aecb-bd370f056c36"
      },
      "source": [
        "#Hidden layers\n",
        "model.add(tf.keras.layers.Dense(200, activation='relu', name='Layer_1'))\n",
        "model.add(tf.keras.layers.Dense(100, activation='relu', name='Layer_2'))\n",
        "\n",
        "#Dropout layer\n",
        "model.add(tf.keras.layers.Dropout(0.5))\n",
        "\n",
        "#Hidden layers\n",
        "model.add(tf.keras.layers.Dense(60, activation='relu', name='Layer_3'))\n",
        "model.add(tf.keras.layers.Dense(30, activation='relu', name='Layer_4'))\n",
        "\n",
        "#Dropout layer\n",
        "model.add(tf.keras.layers.Dropout(0.3))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wjjc0ca_F3Xg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Output layer\n",
        "model.add(tf.keras.layers.Dense(10, activation='softmax', name='Output'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9quA-H6F3Xj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0FMvoNe0F3Xm",
        "colab_type": "text"
      },
      "source": [
        "### Execute Graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TfbxILWQF3Xn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "50b95014-fa92-4ba3-d4cd-4cb010e5055e"
      },
      "source": [
        "#Train the model\n",
        "model.fit(trainX,trainY,          \n",
        "          validation_data=(testX,testY),\n",
        "          epochs=30,\n",
        "          batch_size=32)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/30\n",
            "60000/60000 [==============================] - 7s 116us/sample - loss: 0.5180 - acc: 0.8505 - val_loss: 0.2423 - val_acc: 0.9504\n",
            "Epoch 2/30\n",
            "60000/60000 [==============================] - 7s 113us/sample - loss: 0.2448 - acc: 0.9372 - val_loss: 0.2507 - val_acc: 0.9629\n",
            "Epoch 3/30\n",
            "60000/60000 [==============================] - 7s 114us/sample - loss: 0.1868 - acc: 0.9525 - val_loss: 0.1880 - val_acc: 0.9661\n",
            "Epoch 4/30\n",
            "60000/60000 [==============================] - 7s 116us/sample - loss: 0.1562 - acc: 0.9600 - val_loss: 0.2180 - val_acc: 0.9668\n",
            "Epoch 5/30\n",
            "60000/60000 [==============================] - 7s 113us/sample - loss: 0.1326 - acc: 0.9654 - val_loss: 0.2473 - val_acc: 0.9697\n",
            "Epoch 6/30\n",
            "60000/60000 [==============================] - 7s 113us/sample - loss: 0.1196 - acc: 0.9694 - val_loss: 0.2353 - val_acc: 0.9691\n",
            "Epoch 7/30\n",
            "60000/60000 [==============================] - 7s 113us/sample - loss: 0.1058 - acc: 0.9731 - val_loss: 0.2304 - val_acc: 0.9701\n",
            "Epoch 8/30\n",
            "60000/60000 [==============================] - 7s 115us/sample - loss: 0.0953 - acc: 0.9754 - val_loss: 0.3145 - val_acc: 0.9703\n",
            "Epoch 9/30\n",
            "60000/60000 [==============================] - 7s 113us/sample - loss: 0.0907 - acc: 0.9766 - val_loss: 0.2393 - val_acc: 0.9692\n",
            "Epoch 10/30\n",
            "60000/60000 [==============================] - 7s 113us/sample - loss: 0.0848 - acc: 0.9785 - val_loss: 0.3042 - val_acc: 0.9716\n",
            "Epoch 11/30\n",
            "60000/60000 [==============================] - 7s 113us/sample - loss: 0.0800 - acc: 0.9795 - val_loss: 0.4352 - val_acc: 0.9734\n",
            "Epoch 12/30\n",
            "60000/60000 [==============================] - 7s 112us/sample - loss: 0.0736 - acc: 0.9812 - val_loss: 0.2820 - val_acc: 0.9729\n",
            "Epoch 13/30\n",
            "60000/60000 [==============================] - 7s 115us/sample - loss: 0.0690 - acc: 0.9816 - val_loss: 0.3401 - val_acc: 0.9724\n",
            "Epoch 14/30\n",
            "60000/60000 [==============================] - 7s 119us/sample - loss: 0.0669 - acc: 0.9824 - val_loss: 0.3894 - val_acc: 0.9745\n",
            "Epoch 15/30\n",
            "60000/60000 [==============================] - 7s 118us/sample - loss: 0.0612 - acc: 0.9834 - val_loss: 0.3187 - val_acc: 0.9733\n",
            "Epoch 16/30\n",
            "60000/60000 [==============================] - 7s 115us/sample - loss: 0.0620 - acc: 0.9840 - val_loss: 0.3055 - val_acc: 0.9734\n",
            "Epoch 17/30\n",
            "60000/60000 [==============================] - 7s 113us/sample - loss: 0.0582 - acc: 0.9845 - val_loss: 0.3483 - val_acc: 0.9710\n",
            "Epoch 18/30\n",
            "60000/60000 [==============================] - 7s 114us/sample - loss: 0.0568 - acc: 0.9847 - val_loss: 0.2703 - val_acc: 0.9726\n",
            "Epoch 19/30\n",
            "60000/60000 [==============================] - 7s 113us/sample - loss: 0.0549 - acc: 0.9853 - val_loss: 0.3322 - val_acc: 0.9722\n",
            "Epoch 20/30\n",
            "60000/60000 [==============================] - 7s 113us/sample - loss: 0.0527 - acc: 0.9862 - val_loss: 0.2836 - val_acc: 0.9753\n",
            "Epoch 21/30\n",
            "60000/60000 [==============================] - 7s 113us/sample - loss: 0.0507 - acc: 0.9869 - val_loss: 0.3032 - val_acc: 0.9733\n",
            "Epoch 22/30\n",
            "60000/60000 [==============================] - 7s 114us/sample - loss: 0.0490 - acc: 0.9875 - val_loss: 0.4753 - val_acc: 0.9753\n",
            "Epoch 23/30\n",
            "60000/60000 [==============================] - 7s 115us/sample - loss: 0.0450 - acc: 0.9880 - val_loss: 0.3406 - val_acc: 0.9739\n",
            "Epoch 24/30\n",
            "60000/60000 [==============================] - 7s 116us/sample - loss: 0.0465 - acc: 0.9877 - val_loss: 0.7004 - val_acc: 0.9744\n",
            "Epoch 25/30\n",
            "60000/60000 [==============================] - 7s 114us/sample - loss: 0.0459 - acc: 0.9883 - val_loss: 0.3237 - val_acc: 0.9727\n",
            "Epoch 26/30\n",
            "60000/60000 [==============================] - 7s 114us/sample - loss: 0.0427 - acc: 0.9891 - val_loss: 0.3217 - val_acc: 0.9736\n",
            "Epoch 27/30\n",
            "60000/60000 [==============================] - 7s 117us/sample - loss: 0.0433 - acc: 0.9887 - val_loss: 0.3678 - val_acc: 0.9752\n",
            "Epoch 28/30\n",
            "60000/60000 [==============================] - 7s 115us/sample - loss: 0.0421 - acc: 0.9895 - val_loss: 0.4409 - val_acc: 0.9733\n",
            "Epoch 29/30\n",
            "60000/60000 [==============================] - 7s 113us/sample - loss: 0.0411 - acc: 0.9894 - val_loss: 0.3885 - val_acc: 0.9751\n",
            "Epoch 30/30\n",
            "60000/60000 [==============================] - 7s 113us/sample - loss: 0.0385 - acc: 0.9897 - val_loss: 0.4610 - val_acc: 0.9747\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f475118c828>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    }
  ]
}